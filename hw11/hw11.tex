\documentclass{amsart}

\usepackage{enumitem}
\usepackage{mathtools}

\theoremstyle{definition}
\newtheorem{exercise}{Exercise}

\DeclarePairedDelimiter\abs{\lvert}{\rvert} % absolute value
% Swap the definition of \abs*, so that \abs
% resizes the size of the bars, and the starred version does not.
\makeatletter
\let\oldabs\abs%
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
\makeatother

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\card}[1]{\abs{#1}}
\newcommand{\st}{\mathrel{:}}

\title{MATH 355: Homework 11}
\author{Alexander Lee}

\begin{document}

\maketitle

\begin{exercise}[6.3.1]
  \begin{enumerate}[label={(\alph*)}]
    \item We show that $(g_n)$ converges uniformly on $[0, 1]$ to $g = \lim g_n
      = 0$. Given $\epsilon > 0$, choose $N \in \N$ such that $N > 1/\epsilon$.
      Then, whenever $n \ge \N$ and $x \in [0, 1]$, it follows that
      \[
        \abs{g_n(x) - g(x)} = \abs{\frac{x^n}{n} - 0} = \abs{\frac{x^n}{n}} =
        \frac{x^n}{n} \le \frac{1}{n} \le \frac{1}{N} < \epsilon.
      \]

      $g$ is differentiable since it is the constant function $g(x) = 0$ for all
      $x \in [0, 1]$. Specifically, we have that $g'(x) = 0$ for all $x \in [0,
      1]$.
    \item By the Algebraic Differentiability Theorem, we have that
      \[
        g_n'(x) = \frac{n (nx^{n-1}) - x^n (0)}{n^2} = x^{n-1}.
      \]
      It follows that $(g_n')$ converges on [0, 1] to
      \[
        h(x) = \lim g_n'(x) =
        \begin{cases}
          0 & \text{if}\ 0 \le x < 1 \\
          1 & \text{if}\ x = 1
        \end{cases}.
      \]
      By the contrapositive of the Continuous Limit Theorem, since $h$ is not
      continuous and $g_n'$ is continuous on $[0, 1]$, we have that $(g_n')$
      does not converge uniformly on $[0, 1]$ to $h$. Observe that $h$ and $g'$
      are not the same.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.3.2]
  \begin{enumerate}[label={(\alph*)}]
    \item The pointwise limit of $(h_n)$ is $h(x) = x$. To show that the
      convergence is uniform on $\R$, let $\epsilon > 0$ be arbitrary and choose
      $N \in \N$ such that $N > 1 / \epsilon^2$. Then, whenever $n \ge N$ and $x
      \in \R$, it follows that
      \[
        \abs{h_n(x) - h(x)} = \abs{\sqrt{x^2 - \frac{1}{n}} - x} \le
        \abs{\sqrt{x^2} + \sqrt{\frac{1}{n}} - x} = \sqrt{\frac{1}{n}} \le
        \sqrt{\frac{1}{N}} < \epsilon.
      \]
    \item By the Chain Rule, we have that
      \[
        h_n'(x) = \frac{1}{2 \sqrt{x^2 + \frac{1}{n}}} \cdot 2x =
        \frac{x}{\sqrt{x^2 + \frac{1}{n}}}.
      \]
      It follows that
      \[
        g(x) = \lim h_n'(x) = \lim \frac{x}{\sqrt{x^2 + \frac{1}{n}}} =
        \frac{x}{\sqrt{x^2}} = 1.
      \]
      By the contrapositive of the Differentiable Limit Theorem, since $g(x) = 1
      \neq x = h(x)$ and each $h_n$ is differentiable, it must be that $h_n'$
      does not converge uniformly to $g(x)$ on $\R$, i.e., any neighborhood of
      zero.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.4.2]
  \begin{enumerate}[label={(\alph*)}]
    \item True. Given that $\sum_{n=1}^\infty g_n$ converges uniformly, it
      follows from a special case of the Cauchy Criterion for Uniform
      Convergence of Series that that given $\epsilon > 0$, there exists an $N
      \in \N$ such that whenever $m \ge N$ and $x \in A$, where $A$ is the
      domain of $g_n$, we have that $\abs{g_{m+1}(x)} < \epsilon$. Therefore,
      $(g_n)$ converges uniformly to zero.
    \item True. Given that $0 \le f_n(x) \le g_n(x)$ and $\sum_{n=1}^\infty
      g_n$ converges uniformly, it follows from the Cauchy Criterion for Series
      that given $\epsilon > 0$, there exists an $N \in \N$ such that whenever
      $n > m \ge N$, we have that
      \[
        \abs{f_{m+1}(x) + f_{m+2}(x) + \cdots + f_n(x)} \le \abs{g_{m+1}(x) +
        g_{m+2}(x) + \cdots + g_n(x)} < \epsilon.
      \]
      Therefore, $\sum_{n=1}^\infty f_n$ converges uniformly as well.
    \item False. Consider $f_n(x) = \frac{1}{n^2}$ defined on $\R$. Clearly,
      $\sum_{n=1}^\infty f_n$ converges uniformly on $\R$. Choose $M_n =
      \frac{1}{n}$. Observe that $\abs{\frac{1}{n^2}} \le \frac{1}{n}$ for all
      $x \in \R$, but $\sum_{n=1}^\infty M_n$ diverges.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.4.4]
  TODO
\end{exercise}

\begin{exercise}[6.4.5a]
  Observe that each $\frac{x^n}{n^2}$ is continuous on $[-1, 1]$. Also note that
  for each $n \in \N$, $\abs{\frac{x^n}{n^2}} \le \frac{1}{n^2}$ for all $x \in
  [-1, 1]$. Since $\sum_{n=1}^\infty \frac{1}{n^2}$ converges, it follows from
  the Weierstrass M-Test that $\sum_{n=1}^\infty \frac{x^n}{n^2}$ converges
  uniformly on $[-1, 1]$. Therefore, $h(x)$ is continuous on $[-1, 1]$ by the
  Term-by-term Continuity Theorem.
\end{exercise}

\begin{exercise}[6.5.1]
  \begin{enumerate}[label={(\alph*)}]
    \item $g$ can be rewritten as $g(x) = \sum_{n=1}^\infty {(-1)}^{n+1}
      \frac{x^n}{n}$. If $x = 1$, then $g(x)$ converges by the Alternating
      Series Test. By Theorem 6.5.1, it follows that $g(x)$ converges absolutely
      for any $x \in (-1, 1)$. Therefore, $g$ is defined on $(-1, 1)$.

      Since $g$ converges absolutely on $(-1, 1)$, it follows from Theorem
      6.5.2 that $g$ converge uniformly on $(-1, 1)$. Also note that
      ${(-1)}^{n+1} \frac{x^n}{n}$ is continuous on $(-1, 1)$. By the
      Term-by-term Continuity Theorem, we have that $g$ is continuous on $(-1,
      1)$.

      Since $g(x)$ converges at the point $x = 1$, it follows from Abel's
      Theorem that $g$ converges uniformly on the interval $[0, 1]$. We
      established previously that $g$ also converges uniformly on $(-1, 1)$.
      Therefore, we can conclude that $g$ converges uniformly on $\lparen -1, 1
      \rbrack$ and is thus defined on this set.

      Since $g(x)$ converges uniformly on $\lparen -1, 1 \rbrack$, we can also
      conclude from the Term-by-term Continuity Theorem that $g$ is continuous
      on $\lparen -1, 1 \rbrack$.

      $g(x)$ is not defined when $x = -1$ since this value of $x$ yields the
      harmonic series, which does not converge. Thus, $g$ is not defined on
      $[-1, 1]$ and so cannot even be continuous on this set.

      The power series for $g(x)$ cannot possibly converge for any other points
      $\abs{x} > 1$ because $g(x)$ would be unbounded.

    \item $g'(x) = \sum_{n=1}^\infty {(-1)}^{n+1} \frac{n x^{n-1}}{n} =
      \sum_{n=1}^\infty {(-1)}^{n+1} x^{n-1}$. $g'(x)$ is defined on $(-1, 1)$.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.5.2]
  \begin{enumerate}[label={(\alph*)}]
    \item Consider $a_n = \frac{1}{n!}$. We have that
      \[
        \lim \abs{\frac{x^{n+1}}{(n+1)!} \cdot \frac{n!}{x^n}} = \lim
        \abs{\frac{x}{n+1}} = 0 < 1.
      \]
      By the Ratio Test, it follows $\sum a_n x^n$ converges.
    \item Consider $a_n = {n!}$. We have that
      \[
        \lim \abs{\frac{x^{n+1} (n+1)!}{x^n n!}} = \lim \abs{xn} > 1.
      \]
      By the Ratio Test, it follows that $\sum a_n x^n$ diverges.
    \item TODO
    \item TODO
    \item TODO
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.5.4]
  TODO
\end{exercise}

\end{document}
