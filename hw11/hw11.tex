\documentclass{amsart}

\usepackage{enumitem}
\usepackage{mathtools}

\theoremstyle{definition}
\newtheorem{exercise}{Exercise}

\DeclarePairedDelimiter\abs{\lvert}{\rvert} % absolute value
% Swap the definition of \abs*, so that \abs
% resizes the size of the bars, and the starred version does not.
\makeatletter
\let\oldabs\abs%
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
\makeatother

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\card}[1]{\abs{#1}}
\newcommand{\st}{\mathrel{:}}

\title{MATH 355: Homework 11}
\author{Alexander Lee}

\begin{document}

\maketitle

\begin{exercise}[6.3.1]
  \begin{enumerate}[label={(\alph*)}]
    \item We show that $(g_n)$ converges uniformly on $[0, 1]$ to $g = \lim g_n
      = 0$. Given $\epsilon > 0$, choose $N \in \N$ such that $N > 1/\epsilon$.
      Then, whenever $n \ge \N$ and $x \in [0, 1]$, it follows that
      \[
        \abs{g_n(x) - g(x)} = \abs{\frac{x^n}{n} - 0} = \abs{\frac{x^n}{n}} =
        \frac{x^n}{n} \le \frac{1}{n} \le \frac{1}{N} < \epsilon.
      \]

      $g$ is differentiable since it is the constant function $g(x) = 0$ for all
      $x \in [0, 1]$. Specifically, we have that $g'(x) = 0$ for all $x \in [0,
      1]$.
    \item By the Algebraic Differentiability Theorem, we have that
      \[
        g_n'(x) = \frac{n (nx^{n-1}) - x^n (0)}{n^2} = x^{n-1}.
      \]
      It follows that $(g_n')$ converges on [0, 1] to
      \[
        h(x) = \lim g_n'(x) =
        \begin{cases}
          0 & \text{if}\ 0 \le x < 1 \\
          1 & \text{if}\ x = 1
        \end{cases}.
      \]
      By the contrapositive of the Continuous Limit Theorem, since $h$ is not
      continuous and $g_n'$ is continuous on $[0, 1]$, we have that $(g_n')$
      does not converge uniformly on $[0, 1]$ to $h$. Observe that $h$ and $g'$
      are not the same.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.3.2]
  \begin{enumerate}[label={(\alph*)}]
    \item The pointwise limit of $(h_n)$ is $h(x) = \abs{x}$. To show that the
      convergence is uniform on $\R$, let $\epsilon > 0$ be arbitrary and choose
      $N \in \N$ such that $N > 1 / \epsilon^2$. Then, whenever $n \ge N$ and $x
      \in \R$, it follows that
      \begin{align*}
        \abs{h_n(x) - h(x)} &= \abs{\sqrt{x^2 + \frac{1}{n}} - \abs{x}} \le
        \abs{\sqrt{x^2} + \sqrt{\frac{1}{n}} - \abs{x}} \\
        &= \abs{\abs{x} - \sqrt{\frac{1}{n}} - \abs{x}} = \sqrt{\frac{1}{n}} \le
        \sqrt{\frac{1}{N}} < \epsilon.
      \end{align*}
    \item By the Chain Rule, we have that
      \[
        h_n'(x) = \frac{1}{2 \sqrt{x^2 + \frac{1}{n}}} \cdot 2x =
        \frac{x}{\sqrt{x^2 + \frac{1}{n}}}.
      \]
      It follows that
      \[
        g(x) = \lim h_n'(x) = \lim \frac{x}{\sqrt{x^2 + \frac{1}{n}}} =
        \frac{x}{\sqrt{x^2}} = \frac{x}{\abs{x}} =
        \begin{cases}
          -1 & x < 0 \\
          0 & x = 0 \\
          1 & x > 0
        \end{cases}.
      \]
      Observe that $g(x)$ is not continuous at $x = 0$ but each $h_n'(x)$ is
      continuous at $x = 0$. Therefore, by the contrapositive of the Continuous
      Limit Theorem, it follows that $h_n'(x)$ does not converge uniformly on
      any neighborhood of zero.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.4.2]
  \begin{enumerate}[label={(\alph*)}]
    \item True. Given that $\sum_{n=1}^\infty g_n$ converges uniformly, it
      follows from a special case of the Cauchy Criterion for Uniform
      Convergence of Series that that given $\epsilon > 0$, there exists an $N
      \in \N$ such that whenever $m \ge N$ and $x \in A$, where $A$ is the
      domain of $g_n$, we have that $\abs{g_{m+1}(x)} < \epsilon$. Therefore,
      $(g_n)$ converges uniformly to zero.
    \item True. Given that $0 \le f_n(x) \le g_n(x)$ and $\sum_{n=1}^\infty
      g_n$ converges uniformly, it follows from the Cauchy Criterion for Series
      that given $\epsilon > 0$, there exists an $N \in \N$ such that whenever
      $n > m \ge N$, we have that
      \[
        \abs{f_{m+1}(x) + f_{m+2}(x) + \cdots + f_n(x)} \le \abs{g_{m+1}(x) +
        g_{m+2}(x) + \cdots + g_n(x)} < \epsilon.
      \]
      Therefore, $\sum_{n=1}^\infty f_n$ converges uniformly as well.
    \item False. Consider $f_n(x) = \frac{1}{n^2}$ defined on $\R$. Clearly,
      $\sum_{n=1}^\infty f_n$ converges uniformly on $\R$. Choose $M_n =
      \frac{1}{n}$. Observe that $\abs{\frac{1}{n^2}} \le \frac{1}{n}$ for all
      $x \in \R$, but $\sum_{n=1}^\infty M_n$ diverges.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.4.4]
  Let $g_n(x) = \frac{x^{2n}}{(1 + x^{2n})}$. Observe that if $\abs{x} \ge 1$,
  then $\lim g_n(x) \neq 0$, and so $g(x)$ is not converge for $\abs{x} \ge 1$.
  On the other hand, if $x \in (-1, 1)$, then we have that $\abs{g_n(x)} \le
  x^{2n}$. Since $\sum_{n=0}^\infty x^{2n}$ converges, it follows from the
  Weierstrass M-Test that $g(x) = \sum_{n=0}^\infty g_n(x)$ converges uniformly
  on $(-1, 1)$. Since each $g_n(x)$ is continuous on $(-1, 1)$, by the
  Term-by-term Continuity Theorem, we also have that $g(x)$ is continuous on
  $(-1, 1)$.
\end{exercise}

\begin{exercise}[6.4.5a]
  Observe that each $\frac{x^n}{n^2}$ is continuous on $[-1, 1]$. Also note that
  for each $n \in \N$, $\abs{\frac{x^n}{n^2}} \le \frac{1}{n^2}$ for all $x \in
  [-1, 1]$. Since $\sum_{n=1}^\infty \frac{1}{n^2}$ converges, it follows from
  the Weierstrass M-Test that $\sum_{n=1}^\infty \frac{x^n}{n^2}$ converges
  uniformly on $[-1, 1]$. Therefore, $h(x)$ is continuous on $[-1, 1]$ by the
  Term-by-term Continuity Theorem.
\end{exercise}

\begin{exercise}[6.5.1]
  \begin{enumerate}[label={(\alph*)}]
    \item $g$ can be rewritten as $g(x) = \sum_{n=1}^\infty {(-1)}^{n+1}
      \frac{x^n}{n}$. If $x = 1$, then $g(x)$ converges by the Alternating
      Series Test. By Theorem 6.5.1, it follows that $g(x)$ converges absolutely
      for any $x \in (-1, 1)$. Therefore, $g$ is defined on $(-1, 1)$.

      Since $g$ converges absolutely on $(-1, 1)$, it follows from Theorem
      6.5.2 that $g$ converge uniformly on $(-1, 1)$. Also note that
      ${(-1)}^{n+1} \frac{x^n}{n}$ is continuous on $(-1, 1)$. By the
      Term-by-term Continuity Theorem, we have that $g$ is continuous on $(-1,
      1)$.

      Since $g(x)$ converges at the point $x = 1$, it follows from Abel's
      Theorem that $g$ converges uniformly on the interval $[0, 1]$. We
      established previously that $g$ also converges uniformly on $(-1, 1)$.
      Therefore, we can conclude that $g$ converges uniformly on $\lparen -1, 1
      \rbrack$ and is thus defined on this set.

      Since $g(x)$ converges uniformly on $\lparen -1, 1 \rbrack$, we can also
      conclude from the Term-by-term Continuity Theorem that $g$ is continuous
      on $\lparen -1, 1 \rbrack$.

      $g(x)$ is not defined when $x = -1$ since this value of $x$ yields the
      harmonic series, which does not converge. Thus, $g$ is not defined on
      $[-1, 1]$ and so cannot even be continuous on this set.

      The power series for $g(x)$ cannot possibly converge for any other points
      $\abs{x} > 1$ because $g(x)$ would be unbounded.

    \item $g'(x) = \sum_{n=1}^\infty {(-1)}^{n+1} \frac{n x^{n-1}}{n} =
      \sum_{n=1}^\infty {(-1)}^{n+1} x^{n-1}$. $g'(x)$ is defined on $(-1, 1)$.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.5.2]
  \begin{enumerate}[label={(\alph*)}]
    \item Consider $a_n = \frac{1}{n!}$. We have that
      \[
        \lim \abs{\frac{x^{n+1}}{(n+1)!} \cdot \frac{n!}{x^n}} = \lim
        \abs{\frac{x}{n+1}} = 0 < 1.
      \]
      By the Ratio Test, it follows that $\sum a_n x^n$ converges.
    \item Consider $a_n = {n!}$. Since $\lim a_n x^n \neq 0$ for all $x \in \R$,
      it follows that $\sum a_n x^n$ diverges.
    \item Consider
      \[
        a_n =
        \begin{cases}
          0 & \text{if}\ n\ \text{odd} \\
          1 / {(\frac{n}{2})}^2 & \text{if}\ n\ \text{even}
        \end{cases}.
      \]
      Then, $\sum_{n=1}^\infty a_n x^n = \sum_{n=1}^\infty \frac{x^{2n}}{n^2}$,
      which converges absolutely absolutely for all $x \in [-1, 1]$ and diverges
      off this set.
    \item Impossible. If the power series $\sum a_n x^n$ converges conditionally
      at $x = -1$, then we know that $\sum \abs{a_n {(-1)}^n} = \sum \abs{a_n
      1^n}$ diverges. Therefore, the power series cannot converge absolutely at
      $x = 1$.
    \item Consider
      \[
        a_n =
        \begin{cases}
          0 & \text{if}\ n\ \text{odd} \\
          {(-1)}^\frac{n}{2} / \frac{n}{2} & \text{if}\ n\ \text{even}
        \end{cases}.
      \]
      Then, $\sum_{n=1}^\infty a_n x^n = \sum_{n=1}^\infty \frac{{(-1)}^n
      x^{2n}}{n}$, which converges conditionally at both $x = -1$ and $x = 1$.
  \end{enumerate}
\end{exercise}

\begin{exercise}[6.5.4]
  \begin{enumerate}[label={(\alph*)}]
    \item We first show that $F(x)$ is defined on $(-R, R)$. Observe that
      \[
        0 \le \abs{\frac{a_n}{n+1} x^{n+1}} = \abs{\frac{a_n}{n+1}} \abs{x}
        \abs{x^n} \le \abs{a_n} \abs{x} \abs{x^n} = \abs{x} \abs{a_n x^n}.
      \]
      We now show that $\sum_{n=0}^\infty \abs{x} \abs{a_n x^n}$ converges.
      Recall that $f(x)$ converges on $(-R, R)$. Thus, by Theorem 6.5.1, $f(x)$
      converges uniformly on $(-R, R)$. Since $\sum_{n=0}^\infty \abs{a_n x^n}$
      converges, it follows that $\sum_{n=0}^\infty \abs{x} \abs{a_n x^n}$
      converges. By the Comparison Test, it follows that $\sum_{n=0}^\infty
      \abs{\frac{a_n}{n+1} x^{n+1}}$ converges. Therefore, $F(x)$ converges on
      $(-R, R)$ as well by the Absolute Convergence Test.

      We now show that $F'(x) = f(x)$. Since $f(x)$ converges on $(-R, R)$, it
      follows from Theorem 6.5.5 that $f(x)$ converges uniformly on $(-R, R)$.
      Because $\frac{a_n}{n+1} x^{n+1}$ is differentiable on $(-R, R)$ and
      $F(x)$ converges on $(-R, R)$, we have that $F(x)$ is differentiable and
      $F'(x) = f(x)$.
    \item $g(x) = F(x) + c = (\sum_{n=0}^\infty \frac{a_n}{n+1} x^{n+1}) + c$,
      for some $c \in \R$.
  \end{enumerate}
\end{exercise}

\end{document}
